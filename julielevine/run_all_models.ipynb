{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook to test running 5 different models on the transformed data\n",
    "# Will convert to a single script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the actual training data\n",
    "# import transform\n",
    "\n",
    "# transform.process_data('data/train.csv','data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ML\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# View all cols in jupyter notebook - CAN DROP\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# Training data - has a saleprice column\n",
    "train = pd.read_csv('p_train.csv')        # replace this with sys.argv[1]\n",
    "train.set_index('Id', inplace=True)\n",
    "\n",
    "train_prices = pd.read_csv('prices.csv')\n",
    "train_prices.set_index('Id', inplace=True)\n",
    "\n",
    "# Test data - doesn't have a saleprice column\n",
    "to_guess = pd.read_csv('p_test.csv')      # replace this with sys.argv[2]\n",
    "to_guess.set_index('Id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open all of the pickles to get the params\n",
    "import pickle\n",
    "\n",
    "# Linear\n",
    "with open('linear_params.pkl', 'rb') as f:\n",
    "    param_dict_linear = pickle.load(f)\n",
    "    \n",
    "model_linear = LinearRegression(**param_dict_linear)\n",
    "\n",
    "# RF1\n",
    "with open('rf1_params.pkl', 'rb') as f:\n",
    "    param_dict_rf1 = pickle.load(f)\n",
    "\n",
    "model_rf1 = RandomForestRegressor(**param_dict_rf1)\n",
    "\n",
    "# RF2\n",
    "with open('rf2_params.pkl', 'rb') as f:\n",
    "    param_dict_rf2 = pickle.load(f)\n",
    "\n",
    "model_rf2 = RandomForestRegressor(**param_dict_rf2)\n",
    "\n",
    "# XGBoost\n",
    "with open('xgb_params.pkl', 'rb') as f:\n",
    "    param_dict_xgb = pickle.load(f)\n",
    "\n",
    "model_xgb = RandomForestRegressor(**param_dict_xgb)\n",
    "\n",
    "# GradientBoosting\n",
    "with open('gb_params.pkl', 'rb') as f:\n",
    "    param_dict_gb = pickle.load(f)\n",
    "\n",
    "model_gb = RandomForestRegressor(**param_dict_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training set into 5 folds\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "# keep the indicies of each train and test set in a nested array\n",
    "train_indicies = []\n",
    "test_indicies = []\n",
    "for train_index, test_index in kf.split(train):\n",
    "    train_indicies = train_indicies + [train_index]\n",
    "    test_indicies = test_indicies + [test_index] \n",
    "    \n",
    "# train.iloc[train_indicies[0]]             <-- first 80% train features\n",
    "# train_prices.iloc[train_indicies[0]]      <-- first 80% train labels\n",
    "# train.iloc[test_indicies[0]].shape        <-- first 20% test features\n",
    "# train_prices.iloc[test_indicies[0]].shape <-- first 20% test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "# Data frame to store results\n",
    "linear_results = pd.DataFrame({\"Id\":train_prices.index, \"actual\":train_prices.log_SalePrice})\n",
    "linear_results.set_index('Id',inplace=True)\n",
    "\n",
    "# iterate through the 5 folds to create the first 5 models and gen results\n",
    "for i in range(0,5):\n",
    "    model_linear.fit(train.iloc[train_indicies[i]], train_prices.iloc[train_indicies[i]])  # model on 80%\n",
    "    pred = model_linear.predict(train.iloc[test_indicies[i]])                              # predict on 20%\n",
    "    pred = [i[0] for i in pred]    \n",
    "    model_name = \"model\" + str(i+1)\n",
    "    temp_df = pd.DataFrame({'Id':test_indicies[i], model_name:pred})    # temp DF with ID and new model results\n",
    "    temp_df.set_index('Id', inplace=True)\n",
    "    linear_results = linear_results.merge(temp_df, on='Id', how='left') # add to linear_results DF\n",
    "\n",
    "# create a 6th model - train on all training, predict on all test ('to_guess')\n",
    "model_linear.fit(train, train_prices)\n",
    "pred = model_linear.predict(to_guess)\n",
    "pred = [i[0] for i in pred]\n",
    "temp_df = pd.DataFrame({'Id':to_guess.index, \"model6\":pred})\n",
    "temp_df.set_index('Id', inplace=True)\n",
    "linear_results = linear_results.merge(temp_df, on='Id', how='outer') # add to linear_results DF\n",
    "\n",
    "# reorder cols (actual at the end)\n",
    "linear_results = linear_results[['model1','model2','model3','model4','model5','model6','actual']]\n",
    "\n",
    "# output to a csv\n",
    "linear_results.to_csv('model_outputs/linear_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest 1\n",
    "# Data frame to store results\n",
    "rf1_results = pd.DataFrame({\"Id\":train_prices.index, \"actual\":train_prices.log_SalePrice})\n",
    "rf1_results.set_index('Id',inplace=True)\n",
    "\n",
    "# iterate through the 5 folds to create the first 5 models and gen results\n",
    "for i in range(0,5):\n",
    "    model_rf1.fit(train.iloc[train_indicies[i]], train_prices.iloc[train_indicies[i]].log_SalePrice)  # model on 80%\n",
    "    pred = model_rf1.predict(train.iloc[test_indicies[i]])                              # predict on 20%\n",
    "    pred = [i for i in pred]  \n",
    "    model_name = \"model\" + str(i+1)\n",
    "    temp_df = pd.DataFrame({'Id':test_indicies[i], model_name:pred})    # temp DF with ID and new model results\n",
    "    temp_df.set_index('Id', inplace=True)\n",
    "    rf1_results = rf1_results.merge(temp_df, on='Id', how='left') # add to rf1_results DF\n",
    "\n",
    "# create a 6th model - train on all training, predict on all test ('to_guess')\n",
    "model_rf1.fit(train, train_prices.log_SalePrice)\n",
    "pred = model_rf1.predict(to_guess)\n",
    "pred = [i for i in pred]\n",
    "temp_df = pd.DataFrame({'Id':to_guess.index, \"model6\":pred})\n",
    "temp_df.set_index('Id', inplace=True)\n",
    "rf1_results = rf1_results.merge(temp_df, on='Id', how='outer') # add to rf1_results DF\n",
    "\n",
    "# # reorder cols (actual at the end)\n",
    "rf1_results = rf1_results[['model1','model2','model3','model4','model5','model6','actual']]\n",
    "\n",
    "# # output to a csv\n",
    "rf1_results.to_csv('model_outputs/rf1_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest 2\n",
    "# Data frame to store results\n",
    "rf2_results = pd.DataFrame({\"Id\":train_prices.index, \"actual\":train_prices.log_SalePrice})\n",
    "rf2_results.set_index('Id',inplace=True)\n",
    "\n",
    "# iterate through the 5 folds to create the first 5 models and gen results\n",
    "for i in range(0,5):\n",
    "    model_rf2.fit(train.iloc[train_indicies[i]], train_prices.iloc[train_indicies[i]].log_SalePrice)  # model on 80%\n",
    "    pred = model_rf2.predict(train.iloc[test_indicies[i]])                              # predict on 20%\n",
    "    pred = [i for i in pred]  \n",
    "    model_name = \"model\" + str(i+1)\n",
    "    temp_df = pd.DataFrame({'Id':test_indicies[i], model_name:pred})    # temp DF with ID and new model results\n",
    "    temp_df.set_index('Id', inplace=True)\n",
    "    rf2_results = rf2_results.merge(temp_df, on='Id', how='left') # add to rf2_results DF\n",
    "\n",
    "# create a 6th model - train on all training, predict on all test ('to_guess')\n",
    "model_rf2.fit(train, train_prices.log_SalePrice)\n",
    "pred = model_rf2.predict(to_guess)\n",
    "pred = [i for i in pred]\n",
    "temp_df = pd.DataFrame({'Id':to_guess.index, \"model6\":pred})\n",
    "temp_df.set_index('Id', inplace=True)\n",
    "rf2_results = rf2_results.merge(temp_df, on='Id', how='outer') # add to rf2_results DF\n",
    "\n",
    "# # reorder cols (actual at the end)\n",
    "rf2_results = rf2_results[['model1','model2','model3','model4','model5','model6','actual']]\n",
    "\n",
    "# # output to a csv\n",
    "rf2_results.to_csv('model_outputs/rf2_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "# Data frame to store results\n",
    "xgb_results = pd.DataFrame({\"Id\":train_prices.index, \"actual\":train_prices.log_SalePrice})\n",
    "xgb_results.set_index('Id',inplace=True)\n",
    "\n",
    "# iterate through the 5 folds to create the first 5 models and gen results\n",
    "for i in range(0,5):\n",
    "    model_xgb.fit(train.iloc[train_indicies[i]], train_prices.iloc[train_indicies[i]].log_SalePrice)  # model on 80%\n",
    "    pred = model_xgb.predict(train.iloc[test_indicies[i]])                              # predict on 20%\n",
    "    pred = [i for i in pred]  \n",
    "    model_name = \"model\" + str(i+1)\n",
    "    temp_df = pd.DataFrame({'Id':test_indicies[i], model_name:pred})    # temp DF with ID and new model results\n",
    "    temp_df.set_index('Id', inplace=True)\n",
    "    xgb_results = xgb_results.merge(temp_df, on='Id', how='left') # add to xgb_results DF\n",
    "\n",
    "# create a 6th model - train on all training, predict on all test ('to_guess')\n",
    "model_xgb.fit(train, train_prices.log_SalePrice)\n",
    "pred = model_xgb.predict(to_guess)\n",
    "pred = [i for i in pred]\n",
    "temp_df = pd.DataFrame({'Id':to_guess.index, \"model6\":pred})\n",
    "temp_df.set_index('Id', inplace=True)\n",
    "xgb_results = xgb_results.merge(temp_df, on='Id', how='outer') # add to xgb_results DF\n",
    "\n",
    "# # reorder cols (actual at the end)\n",
    "xgb_results = xgb_results[['model1','model2','model3','model4','model5','model6','actual']]\n",
    "\n",
    "# # output to a csv\n",
    "xgb_results.to_csv('model_outputs/xgb_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GradientBoost\n",
    "# Data frame to store results\n",
    "gb_results = pd.DataFrame({\"Id\":train_prices.index, \"actual\":train_prices.log_SalePrice})\n",
    "gb_results.set_index('Id',inplace=True)\n",
    "\n",
    "# iterate through the 5 folds to create the first 5 models and gen results\n",
    "for i in range(0,5):\n",
    "    model_gb.fit(train.iloc[train_indicies[i]], train_prices.iloc[train_indicies[i]].log_SalePrice)  # model on 80%\n",
    "    pred = model_gb.predict(train.iloc[test_indicies[i]])                              # predict on 20%\n",
    "    pred = [i for i in pred]  \n",
    "    model_name = \"model\" + str(i+1)\n",
    "    temp_df = pd.DataFrame({'Id':test_indicies[i], model_name:pred})    # temp DF with ID and new model results\n",
    "    temp_df.set_index('Id', inplace=True)\n",
    "    gb_results = gb_results.merge(temp_df, on='Id', how='left') # add to gb_results DF\n",
    "\n",
    "# create a 6th model - train on all training, predict on all test ('to_guess')\n",
    "model_gb.fit(train, train_prices.log_SalePrice)\n",
    "pred = model_gb.predict(to_guess)\n",
    "pred = [i for i in pred]\n",
    "temp_df = pd.DataFrame({'Id':to_guess.index, \"model6\":pred})\n",
    "temp_df.set_index('Id', inplace=True)\n",
    "gb_results = gb_results.merge(temp_df, on='Id', how='outer') # add to gb_results DF\n",
    "\n",
    "# # reorder cols (actual at the end)\n",
    "gb_results = gb_results[['model1','model2','model3','model4','model5','model6','actual']]\n",
    "\n",
    "# # output to a csv\n",
    "gb_results.to_csv('model_outputs/gb_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
